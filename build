#!/usr/bin/env python3

"""build

Usage:
  build [--drafts] [--cache=<dir>] [--out=<dir>] [--root=<url>]
  build (-h | --help)

Options:
  -h --help       Show this screen.
  --drafts        Include draft notes as well.
  --cache=<dir>   Directory to cache generated HTML in [default: _cache]
  --out=<dir>     Directory to generate site in [default: _site]
  --root=<url>    Root of the website [default: https://weeknotes.barrucadu.co.uk/]

"""

import hashlib
import jinja2
import json
import pypandoc
import shutil
import subprocess
import sys
import yaml

from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from docopt import docopt
from pathlib import Path

args = docopt(__doc__)
OUT_DIR = args["--out"]
BASE_HREF = args["--root"]
DRAFT_MODE = args["--drafts"]
CACHE_DIR = args["--cache"]

JINJA2_ENV = jinja2.Environment(
    autoescape=jinja2.select_autoescape(["html", "xml"]),
    loader=jinja2.FileSystemLoader("_templates"),
)

SITE_NAME = "barrucadu's weeknotes"
NOTE_DIR = "notes"

DATE_ISO_FORMAT = "%Y-%m-%d"
DATE_PP_FORMAT = "%b %-d, %Y"


def pandocise_note(link, text):
    """Render a note's content using pandoc."""

    text_hash = hashlib.sha256()
    text_hash.update(text.encode())
    cache_file = Path(CACHE_DIR, f"sha256-{text_hash.hexdigest()}.json")
    try:
        cached = json.loads(cache_file.read_text())
        return cached["html"]
    except (OSError, json.decoder.JSONDecodeError):
        html = pypandoc.convert_text(
            text,
            "html",
            format="markdown",
            filters=[
                "pandoc-filter-transform-code",
            ],
            extra_args=[
                "--no-highlight",
                "--section-divs",
            ],
        )

        # this can't be done as a pandoc filter sadly, because the footnote
        # links don't exist when the filter runs
        html = html.replace('href="#fn', f'href="{link}#fn')

        try:
            cache_file.write_text(json.dumps({"html": html}))
        except OSError as err:
            print(f"could not cache generated HTML for {link}: {err.strerror}")

        return html


def render(link, template, **metadata):
    """Render a jinja2 template."""

    Path(OUT_DIR, link).write_text(
        JINJA2_ENV.get_template(template).render(
            base_href=BASE_HREF,
            hashed_links=HASHED_LINKS,
            site_name=SITE_NAME,
            link=link,
            permalink=f"{BASE_HREF}{link}",
            **metadata,
        )
    )


ALL_NOTES = []
for fpath in Path("notes").iterdir():
    if not fpath.is_file():
        continue

    lines = fpath.read_text().splitlines()
    metadata_end_idx = lines[1:].index("---") + 1
    text_start_idx = metadata_end_idx + 1
    note = yaml.load("\n".join(lines[1:metadata_end_idx]), Loader=yaml.SafeLoader)

    note["slug"] = fpath.stem
    note["link"] = f"{NOTE_DIR}/{note['slug']}.html"
    note["permalink"] = f"{BASE_HREF}{note['link']}"

    note["title"] = f"#{note['slug']}"
    if "annual_special_for" in note:
        note["title"] += f" â€” End of {note['annual_special_for']} Special"

    if "date" not in note:
        print(f"missing date in metadata for {fpath}")
        sys.exit(1)

    note["published_iso"] = note["date"].strftime(DATE_ISO_FORMAT)
    note["published_pp"] = note["date"].strftime(DATE_PP_FORMAT)

    # render the body
    note["text"] = "\n".join(lines[text_start_idx:]) + "\n"
    note["body"] = pandocise_note(note["link"], note["text"])

    if note.get("draft", False) and not DRAFT_MODE:
        continue
    ALL_NOTES.append(note)
ALL_NOTES.sort(key=lambda note: note["date"], reverse=True)

prev = None
for note in reversed(ALL_NOTES):
    if prev is not None:
        note["prev"] = prev
        prev["next"] = note
    prev = note


###############################################################################
# Here be effects

shutil.rmtree(OUT_DIR, ignore_errors=True)
shutil.copytree("static", OUT_DIR, dirs_exist_ok=True)
Path(OUT_DIR, NOTE_DIR).mkdir(exist_ok=True)

HASHED_LINKS = {}
for fpath in Path("hashed-static").iterdir():
    if not fpath.is_file():
        continue

    file_hash = hashlib.sha256()
    with fpath.open("rb") as f:
        while True:
            data = f.read(65536)
            if not data:
                break
            file_hash.update(data)
    HASHED_LINKS[fpath.name] = (
        f"{fpath.stem}-sha256-{file_hash.hexdigest()}{fpath.suffix}"
    )
    shutil.copy(fpath, Path(OUT_DIR, HASHED_LINKS[fpath.name]))


render("robots.txt", "robots.txt")
render("sitemap.xml", "sitemap.xml", notes=ALL_NOTES)

render("index.html", "index.html", title=SITE_NAME, notes=ALL_NOTES)
render(
    "atom.xml",
    "atom.xml",
    title=SITE_NAME,
    notes=ALL_NOTES[:10],
    feed_date=ALL_NOTES[0]["published_iso"],
)

for note in ALL_NOTES:
    render(note["link"], "note.html", title=note["title"], note=note)
